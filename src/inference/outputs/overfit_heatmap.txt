Read successful, here are the characteristics of your model: 
{'model_name': 'VideoMambaPose', 'project_dir': '/home/xinlei/Projects/KITE_MambaPose/Video_Pose/3_VideoMambaPose/src/models/experiments/latent_space_regression_with_linear', 'model_type': 'latent_space_linear_regression', 'full_debug': False, 'show_gradients': True, 'embed_channels': 192, 'num_mamba_blocks': 12, 'num_deconv': 2, '2d_deconv': True, 'deconv_channels': 192, 'num_conv': 2, 'conv_channels': 256, 'joint_regressor': True, 'hidden_channels': 512, 'output_dimensions': 2, 'dropout': False, 'dropout_percent': 0.25, 'num_hidden_layers': 3, 'epoch_number': 300, 'batch_size': 4, 'learning_rate': 0.1, 'scheduler': True, 'start_epoch': 1, 'num_cpus': 1, 'num_gpus': 1, 'parallelize': False, 'checkpoint_directory': '/home/xinlei/Projects/KITE_MambaPose/Video_Pose/3_VideoMambaPose/src/models/experiments/heatmap/checkpoint', 'checkpoint_name': 'tanh_overfit_model', 'follow_up': False, 'previous_training_epoch': 1, 'previous_checkpoint': '', 'dataset_name': 'JHMDB', 'data_path': '/home/xinlei/Projects/KITE_MambaPose/Video_Pose/3_VideoMambaPose/data/JHMDB', 'annotations_path': '/home/xinlei/Projects/KITE_MambaPose/Video_Pose/3_VideoMambaPose/data/JHMDB_old/annotations', 'use_videos': False, 'skip': ['wave'], 'num_frames': 16, 'channels': 3, 'image_height': 240, 'image_width': 320, 'image_tensor_height': 192, 'image_tensor_width': 256, 'patch_number': 192, 'patch_size': 16, 'jump': 1, 'joint_number': 15, 'real_job': False, 'normalized': True, 'default': False, 'min_norm': -1}
[2024-06-09 00:33:20,768] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
The joints are normalized: True.
         The joints are normalized with the default: False
The joints taken are not normalized
tensor([[120.9150,  49.0815],
        [133.8845,  88.3518],
        [119.3713,  39.0847],
        [131.2572,  56.0000],
        [111.6572,  60.5715],
        [140.5143, 101.3715],
        [129.2571, 102.0000],
        [144.8582,  66.8008],
        [113.4855,  74.1127],
        [153.0280, 137.8268],
        [137.6580, 136.0663],
        [146.5699,  46.9497],
        [125.0621,  51.7055],
        [149.5429, 169.6568],
        [137.7714, 167.7695]], dtype=torch.float64)
The passed width and height are  320 240
Video saved as results/normalized_pull_ups
Use checkpoint: False
Checkpoint number: 0
HeatMapVideoMambaPose(
  (mamba): VisionMamba(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 192, kernel_size=(1, 16, 16), stride=(1, 16, 16))
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (head_drop): Identity()
    (head): Linear(in_features=192, out_features=1000, bias=True)
    (drop_path): DropPath()
    (layers): ModuleList(
      (0-1): 2 x Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=192, out_features=768, bias=False)
          (conv1d): Conv1d(384, 384, kernel_size=(4,), stride=(1,), padding=(3,), groups=384)
          (act): SiLU()
          (x_proj): Linear(in_features=384, out_features=44, bias=False)
          (dt_proj): Linear(in_features=12, out_features=384, bias=True)
          (conv1d_b): Conv1d(384, 384, kernel_size=(4,), stride=(1,), padding=(3,), groups=384)
          (x_proj_b): Linear(in_features=384, out_features=44, bias=False)
          (dt_proj_b): Linear(in_features=12, out_features=384, bias=True)
          (out_proj): Linear(in_features=384, out_features=192, bias=False)
        )
        (norm): RMSNorm()
        (drop_path): Identity()
      )
      (2-11): 10 x Block(
        (mixer): Mamba(
          (in_proj): Linear(in_features=192, out_features=768, bias=False)
          (conv1d): Conv1d(384, 384, kernel_size=(4,), stride=(1,), padding=(3,), groups=384)
          (act): SiLU()
          (x_proj): Linear(in_features=384, out_features=44, bias=False)
          (dt_proj): Linear(in_features=12, out_features=384, bias=True)
          (conv1d_b): Conv1d(384, 384, kernel_size=(4,), stride=(1,), padding=(3,), groups=384)
          (x_proj_b): Linear(in_features=384, out_features=44, bias=False)
          (dt_proj_b): Linear(in_features=12, out_features=384, bias=True)
          (out_proj): Linear(in_features=384, out_features=192, bias=False)
        )
        (norm): RMSNorm()
        (drop_path): DropPath()
      )
    )
    (norm_f): RMSNorm()
  )
  (deconv): Deconv(
    (conv_layers): Sequential(
      (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(256, 15, kernel_size=(1, 1), stride=(1, 1))
    )
    (deconv_layers): Sequential(
      (0): ConvTranspose2d(192, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)
      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
    )
  )
  (joints): JointOutput(
    (regressor): Sequential(
      (0): Linear(in_features=3072, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=2, bias=True)
      (3): Tanh()
    )
  )
)
Are the last two outputs the same?:  tensor([[True, True],
        [True, True],
        [True, True],
        [True, True],
        [True, True],
        [True, True],
        [True, True],
        [True, True],
        [True, True],
        [True, True],
        [True, True],
        [True, True],
        [True, True],
        [True, True],
        [True, True]])
output tensor([[[-1.,  1.],
         [-1.,  1.],
         [-1.,  1.],
         [-1.,  1.],
         [-1.,  1.],
         [-1.,  1.],
         [-1.,  1.],
         [-1.,  1.],
         [-1.,  1.],
         [-1.,  1.],
         [-1.,  1.],
         [-1.,  1.],
         [-1.,  1.],
         [-1.,  1.],
         [-1.,  1.]]], device='cuda:0')
{'model_name': 'VideoMambaPose', 'project_dir': '/home/xinlei/Projects/KITE_MambaPose/Video_Pose/3_VideoMambaPose/src/models/experiments/latent_space_regression_with_linear', 'model_type': 'latent_space_linear_regression', 'full_debug': False, 'show_gradients': True, 'embed_channels': 192, 'num_mamba_blocks': 12, 'num_deconv': 2, '2d_deconv': True, 'deconv_channels': 192, 'num_conv': 2, 'conv_channels': 256, 'joint_regressor': True, 'hidden_channels': 512, 'output_dimensions': 2, 'dropout': False, 'dropout_percent': 0.25, 'num_hidden_layers': 3, 'epoch_number': 300, 'batch_size': 4, 'learning_rate': 0.1, 'scheduler': True, 'start_epoch': 1, 'num_cpus': 1, 'num_gpus': 1, 'parallelize': False, 'checkpoint_directory': '/home/xinlei/Projects/KITE_MambaPose/Video_Pose/3_VideoMambaPose/src/models/experiments/heatmap/checkpoint', 'checkpoint_name': 'tanh_overfit_model', 'follow_up': False, 'previous_training_epoch': 1, 'previous_checkpoint': '', 'dataset_name': 'JHMDB', 'data_path': '/home/xinlei/Projects/KITE_MambaPose/Video_Pose/3_VideoMambaPose/data/JHMDB', 'annotations_path': '/home/xinlei/Projects/KITE_MambaPose/Video_Pose/3_VideoMambaPose/data/JHMDB_old/annotations', 'use_videos': False, 'skip': ['wave'], 'num_frames': 16, 'channels': 3, 'image_height': 240, 'image_width': 320, 'image_tensor_height': 192, 'image_tensor_width': 256, 'patch_number': 192, 'patch_size': 16, 'jump': 1, 'joint_number': 15, 'real_job': False, 'normalized': True, 'default': False, 'min_norm': -1}
<class 'dict'>
<class 'int'>
-1
The passed width and height are  320 240
Video saved as results/1predicted
